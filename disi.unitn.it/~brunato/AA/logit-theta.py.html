#!/usr/bin/env python2
# -*- coding: utf-8 -*-
#
# logit-theta.py
#
# Esperimenti con la regressione logistica, discesa lungo il gradiente,
# scelta della soglia ottimale.
#
# Richiede la presenza del file "transfusion.data" (dal repository UCI)
# nella stessa directory
#
# Esecuzione:
#    python2 logit-theta.py
# oppure
#    chmod 755 logit-theta.py   <--- una tantum
#    ./logit-theta.py
#
# Attenzione: il codice serve esclusivamente a scopi didattici
# e non è adatto a un utilizzo "serio": mancano molti accorgimenti e ottimizzazioni
# che lo renderebbero molto più complesso e difficile da capire.

############################################
#
# Moduli

# Lettura del file CSV
import pandas

# Algebra delle matrici
import numpy as np

# Tracciamento di grafici
import matplotlib.pyplot as plt

############################################
#
# Parametri

# Frazione di dati da usare per l'addestramento del modello
# (il resto dervirà per la validazione)
training_fraction = .5

# Learning rate iniziale
eta = 1.0e-3

############################################
#
# Lettura dei dati

# Il file è già in formato CSV corretto, con una riga di intestazione,
# ma i dati sono interi, quindi dobbiamo specificare che
# li vogliamo in virgola mobile.
dataset = pandas.read_csv('transfusion.data', dtype=np.float64)

# Trasformiamo il dataset in una matrice Numpy
D = dataset.as_matrix()

# Mescoliamo le righe del dataset
np.random.shuffle(D)

# Ricaviamo il numero di righe per l'addestramento
m = len(D)
m_t = int(np.round(training_fraction * m))

# Le prime m_t righe del dataset rimescolato servono per l'addestramento (X_t, y_t)
D_t = D[:m_t]
X_t = D_t[:,:4]
y_t = D_t[:,4]

# Le righe rimanenti servono per la validazione (X_v, y_v)
D_v = D[m_t:]
X_v = D_v[:,:4]
y_v = D_v[:,4]

# Normalizziamo le colonne di input riscalandole rispetto al loro massimo
for i in range(4):
    # Il coefficiente di scala per una colonna è dato dal massimo
    # che la colonna assume nel sottoinsieme di addestramento
    s = np.max(X_t[:,i])
    # Le corrispondenti colonne dell'insieme di addestramento e di validazione vanno riscalate
    # rispetto allo stesso valore
    X_t[:,i] /= s
    X_v[:,i] /= s


############################################
#
# Funzioni

# La funzione sigmoide 1 / (1 + e^-t)
def sigmoid(t):
    return 1.0 / (1.0 + np.exp(-t))

# Data una matrice di input e un vettore di pesi,
# calcola il vettore delle previsioni del modello logit
def prediction(X, beta):
    return sigmoid(X.dot(beta))

# Dato il vettore degli output desiderati y, quello
# degli output previsti yp, la matrice di input e
# l'indice del peso k, calcola la derivata parziale rispetto a beta_k
# della soma degli scarti al quadrato
def partial_derivative(y, yp, X, k):
    return 2.0 * np.sum((yp - y) * yp * (1.0 - yp) * X[:,k])

# Costruisce il vettore delle derivate parziali
def gradient(y, yp, X):
    return np.array([partial_derivative(y, yp, X, k)
                        for k in range(4)])

# Dato il vettore degli output desiderati y e quello
# degli output previsti yp, restituisce l'RMSE.
def RMSE(y, yp):
    return np.sqrt(np.sum((y - yp)**2) / len(y))

# Dato il vettore delle y "vere" yv, quello delle y "predette" vp
# (contenente il valore di uscita della sigmoide) e una soglie theta,
# calcolare la matrice di confusione relativa alla soglia
def confusion(yv, yp, theta):
	return {
		'TP': np.sum(np.logical_and(yv == 1, yp >= theta)),
		'FN': np.sum(np.logical_and(yv == 1, yp < theta)),
		'FP': np.sum(np.logical_and(yv == 0, yp >= theta)),
		'TN': np.sum(np.logical_and(yv == 0, yp < theta))
	}

# Data la matrice di confusione C, calcoliamo l'accuratezza, la precisione, la sensibilità
# e la False Positive Ratio (FPR)
def accuracy(C):
	return float(C['TP']+C['TN']) / (C['TP']+C['TN']+C['FP']+C['FN'])
def precision(C):
	d = C['TP']+C['FP']
	return float(C['TP']) / d if d > 0 else 1
def sensitivity(C):
	d = C['TP']+C['FN']
	return float(C['TP']) / d if d > 0 else 1
def FPR(C):
	d = C['FP']+C['TN']
	return float(C['FP']) / d if d > 0 else 0


############################################
#
# Discesa lungo il gradiente

# Inizializzazione dei pesi: beta può partire da valori casuali, oppure da zero.
#beta = np.zeros(4)
beta = np.random.random(4)

# Prima previsione yp_t e RMSE corrispondente error_t sull'insieme di addestramento
yp_t = prediction(X_t,beta)
error_t = RMSE(y_t, yp_t)

# Prima previsione yp_v e RMSE corrispondente error_v sull'insieme di validazione
yp_v = prediction(X_v, beta)
error_v = RMSE(y_v, yp_v)

# Ricordiamo, nel corso della discesa lungo il gradiente,
# quali coefficienti beta hanno ottenuto il minor errore sull'insieme di validazione
best_RMSE = error_v
best_beta = beta

# Manteniamo due liste che ci permetteranno di tracciare il progresso degli errori di
# addestramento e validazione mentre la discesa lungo il gradiente ha luogo.
training_errors = [error_t]
validation_errors = [error_v]


# Ripetizione del passo di discesa. Fissiamo un limite a 200 iterazioni per convenienza
for i in range(200):

    # Calcolo del gradiente
    grad = gradient(y_t, yp_t, X_t)

    # Ricerca di un passo eta adeguato: questo ciclo sposta le beta
    # attuali in direzione opposta al gradiente, e ripete l'operazione
    # dimezzando il passo se le cose peggiorano.
    while True:

        # Sposta il vettore dei pesi contro il gradiente
        beta1 = beta - eta * grad

        # Calcola la nuova previsione e il nuovo errore
        yp1 = prediction(X_t, beta1)
        error1 = RMSE(y_t, yp1)

        # Se il passo peggiora le cose, allora eta è troppo grande: dimezzare e riprovare
        if error1 >= error_t:
            eta /= 2
            # Se però eta è diventato troppo piccolo, allora smettiamo di provarci:
            if eta < 1.0e-20:
                break

        # Altrimenti, eta è adeguato
        else:
            # Aumentare leggermente eta per la prossima iterazione
            eta *= 1.1
            # Aggiornare i valori di beta, yp ed error_t
            error_t = error1
            beta = beta1
            yp_t = yp1
            # Uscire dal ciclo interno e passare all'iterazione successiva
            break

    # Se eta è diventato troppo piccolo, terminiamo prematuramente anche il ciclo esterno
    if eta < 1.0e-20:
        break

    # Calcoliamo anche la previsione e l'errore per l'insieme di validazione
    # con le nuove beta
    yp_v = prediction(X_v, beta)
    error_v = RMSE(y_v, yp_v)

    # Aggiorniamo se necessario i pesi migliori sul dataset di validazione
    if error_v < best_RMSE:
        best_RMSE = error_v
        best_beta = beta

    # Stampiamo l'errore corrente
    print (error_t, error_v)

    # Aggiungiamo i due errori alle rispettive liste per il diagramma a fine ciclo.
    training_errors.append(error_t)
    validation_errors.append(error_v)

############################################
#
# Tracciamento degli errori di addestramento

# Curva dell'RMSE sui dati di addestramento
plt.plot(training_errors, label='Training')

# Curva dell'RMSE sui dati di validazione
plt.plot(validation_errors, label='Validation')

# Aggiungiamo una legenda, una griglia e le etichette degli assi
plt.legend()
plt.grid()
plt.xlabel('Training iteration')
plt.ylabel('RMSE')

# Visualizziamo il grafico.
plt.show()

################################################
#
# Analisi delle predizioni per il miglior vettore di pesi

# Calcolo delle predisioni sull'insieme di validazione per i migliori beta trovati
yp_v = prediction(X_v, best_beta)

# Accumuliamo i vari indici di prestazione al variare della soglia theta fra 0 e 1
thetas = []
accuracies = []
precisions = []
sensitivities = []
FPRs = []
theta = 0
for i in range(101):
    theta = i * .01
    C = confusion(y_v, yp_v, theta)
    thetas.append(theta)
    accuracies.append(accuracy(C))
    precisions.append(precision(C))
    sensitivities.append(sensitivity(C))
    FPRs.append(FPR(C))

# Rappresentiamo l'andamento degli indici su un grafico
plt.plot(thetas, accuracies, label='accuracy')
plt.plot(thetas, precisions, label='precision')
plt.plot(thetas, sensitivities, label='sensitivity')
plt.xlabel('Threshold ($\\theta$)')
plt.ylabel('Value')
plt.legend()
plt.grid()
plt.show()

# Rappresentiamo la curva ROC
plt.plot(FPRs, sensitivities)
plt.xlabel('False positive ratio (FPR)')
plt.ylabel('True positive ratio (TPR, sensitivity)')
plt.grid()
plt.show()
